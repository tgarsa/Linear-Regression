{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7739315d",
   "metadata": {},
   "source": [
    "# Numerical Approach\n",
    "\n",
    "We use the minimization of a mean squared error function to calculate the linear regression model. \n",
    "\n",
    "The idea is to calculate the cost function (mse) and calculate the derivative of this function, the gradient, to understand how we can reduce this cost function. A pure numerical approach without any additional library to calculate any step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c0e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tradicional imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Additional tools \n",
    "import copy, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9adf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../data/linear_numeric_summarized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5090edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1067163490</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073181139</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1074271959</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1074896711</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1077476451</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target  age  gender         A         B         C         D  \\\n",
       "0  1067163490       0   47       1  2.000000  4.333333  1.000000  1.333333   \n",
       "1  1073181139       2   60       1  3.333333  3.000000  3.333333  1.333333   \n",
       "2  1074271959       0   57       0  2.000000  4.666667  1.000000  1.000000   \n",
       "3  1074896711       0   74       0  2.333333  5.000000  1.000000  2.000000   \n",
       "4  1077476451       0   79       1  3.666667  5.000000  1.000000  2.000000   \n",
       "\n",
       "          E         F    G  \n",
       "0  3.000000  3.000000  2.5  \n",
       "1  3.333333  4.333333  3.0  \n",
       "2  4.333333  2.000000  2.0  \n",
       "3  4.333333  1.666667  2.5  \n",
       "4  3.666667  1.666667  2.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af33b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.         4.33333333 1.         ... 3.         3.         2.5       ]\n",
      " [3.33333333 3.         3.33333333 ... 3.33333333 4.33333333 3.        ]\n",
      " [2.         4.66666667 1.         ... 4.33333333 2.         2.        ]\n",
      " ...\n",
      " [3.33333333 2.         2.33333333 ... 4.33333333 2.66666667 2.5       ]\n",
      " [2.         4.         2.         ... 2.66666667 2.33333333 1.        ]\n",
      " [1.         1.33333333 1.33333333 ... 1.33333333 2.66666667 1.5       ]]\n",
      "(203, 7)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.iloc[:, 4:])\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ebe5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 0 0 0 0 3 0 0 0 0 0 4 0 0 0 0 0 4 0 1 4 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 2 0 2 1 0 0 1 0 1 0 0 1 2 0 0 0 1 1 4 0 1 0 1 0 0 1 1 2 0 0 4 0 0 0 3 0\n",
      " 0 0 0 5 1 2 0 0 0 0 0 1 1 0 0 3 0 5 0 1 0 5 2 1 3 0 5 0 3 1 1 2 1 0 0 5 0\n",
      " 1 3 0 1 0 2 0 0 0 0 4 1 1 0 4 1 0 2 2 1 1 0 3 3 2 1 0 3 1 1 0 0 2 2 2 0 0\n",
      " 0 0 5 0 1 3 2 0 0 4 2 5 2 0 2 0 1 1 1 0 0 0 0 1 0 1 5 0 1 1 0 0 1 5 0 5 2\n",
      " 0 1 5 0 0 0 0 2 1 2 1 2 1 4 2 3 0 3]\n",
      "(203,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['target'])\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc3b2f",
   "metadata": {},
   "source": [
    "## Computing Cost\n",
    "The term 'cost' in this assignment might be a little confusing since the data is housing cost. Here, cost is a measure how well our model is predicting the target price of the house. The term 'price' is used for housing data.\n",
    "\n",
    "The equation for cost with one variable is:\n",
    "  $$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\tag{1}$$ \n",
    " \n",
    "where \n",
    "  $$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{2}$$\n",
    "  \n",
    "- $f_{w,b}(x^{(i)})$ is our prediction for example $i$ using parameters $w,b$.  \n",
    "- $(f_{w,b}(x^{(i)}) -y^{(i)})^2$ is the squared difference between the target value and the prediction.   \n",
    "- These differences are summed over all the $m$ examples and divided by `2m` to produce the cost, $J(w,b)$.  \n",
    ">Note, in lecture summation ranges are typically from 1 to m, while code will be from 0 to m-1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf52c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1a1dd",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.1\"></a>\n",
    "## Gradient descent summary\n",
    "So far in this course, you have developed a linear model that predicts $f_{w,b}(x^{(i)})$:\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\n",
    "In linear regression, you utilize input training data to fit the parameters $w$,$b$ by minimizing a measure of the error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$. The measure is called the $cost$, $J(w,b)$. In training you measure the cost over all of our training samples $x^{(i)},y^{(i)}$\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456b95b",
   "metadata": {},
   "source": [
    "\n",
    "In lecture, *gradient descent* was described as:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "where, parameters $w$, $b$ are updated simultaneously.  \n",
    "The gradient is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba7591a",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.2\"></a>\n",
    "## Implement Gradient Descent\n",
    "You will implement gradient descent algorithm for one feature. You will need three functions. \n",
    "- `compute_gradient` implementing equation (4) and (5) above\n",
    "- `compute_cost` implementing equation (2) above (code from previous lab)\n",
    "- `gradient_descent`, utilizing compute_gradient and compute_cost\n",
    "\n",
    "Conventions:\n",
    "- The naming of python variables containing partial derivatives follows this pattern,$\\frac{\\partial J(w,b)}{\\partial b}$  will be `dj_db`.\n",
    "- w.r.t is With Respect To, as in partial derivative of $J(wb)$ With Respect To $b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515da5d",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.3\"></a>\n",
    "### compute_gradient\n",
    "<a name='ex-01'></a>\n",
    "`compute_gradient`  implements (4) and (5) above and returns $\\frac{\\partial J(w,b)}{\\partial w}$,$\\frac{\\partial J(w,b)}{\\partial b}$. The embedded comments describe the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22dcc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"   \n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):   \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac9c9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.0788177339901477\n",
      "dj_dw at initial w,b: \n",
      " [-3.28571429 -3.44170772 -2.45977011 -1.48275862 -3.71592775 -3.38095238\n",
      " -2.31280788]\n"
     ]
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "# Compute and display gradient with w and b initialized to zeros\n",
    "w_init = np.zeros(n)\n",
    "b_init = 0.\n",
    "\n",
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X, y, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d76d18e",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.5\"></a>\n",
    "###  Gradient Descent\n",
    "Now that gradients can be computed,  gradient descent, described in equation (3) above can be implemented below in `gradient_descent`. The details of the implementation are described in the comments. Below, you will utilize this function to find optimal values of $w$ and $b$ on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b87321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, \n",
    "                     y, \n",
    "                     w_in, \n",
    "                     b_in, \n",
    "                     cost_function, \n",
    "                     gradient_function, \n",
    "                     alpha, \n",
    "                     num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a13f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20d18195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     1.64   \n",
      "Iteration 5000: Cost     1.05   \n",
      "Iteration 10000: Cost     1.01   \n",
      "Iteration 15000: Cost     0.99   \n",
      "Iteration 20000: Cost     0.98   \n",
      "Iteration 25000: Cost     0.97   \n",
      "Iteration 30000: Cost     0.97   \n",
      "Iteration 35000: Cost     0.97   \n",
      "Iteration 40000: Cost     0.96   \n",
      "Iteration 45000: Cost     0.96   \n",
      "b,w found by gradient descent: 0.18,[ 0.21150549 -0.25840856  0.1260959  -0.00920062 -0.00349122  0.29104689\n",
      "  0.03140121] \n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 50000\n",
    "alpha = 5.0e-5\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train, \n",
    "                                            y_train, \n",
    "                                            initial_w, \n",
    "                                            initial_b,\n",
    "                                            compute_cost, \n",
    "                                            compute_gradient, \n",
    "                                            alpha, \n",
    "                                            iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959b111c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0.54, target value: 0\n",
      "prediction: 1.86, target value: 2\n",
      "prediction: 0.14, target value: 0\n",
      "prediction: 0.04, target value: 0\n",
      "prediction: 0.32, target value: 0\n",
      "prediction: 0.68, target value: 0\n",
      "prediction: 1.75, target value: 0\n",
      "prediction: 1.22, target value: 3\n",
      "prediction: 1.24, target value: 0\n",
      "prediction: 0.37, target value: 0\n",
      "prediction: -0.41, target value: 0\n",
      "prediction: 0.39, target value: 0\n",
      "prediction: 1.12, target value: 0\n",
      "prediction: 0.70, target value: 4\n",
      "prediction: -0.11, target value: 0\n",
      "prediction: 1.69, target value: 0\n",
      "prediction: -0.20, target value: 0\n",
      "prediction: 0.91, target value: 0\n",
      "prediction: 1.19, target value: 0\n",
      "prediction: 2.06, target value: 4\n",
      "prediction: 0.36, target value: 0\n",
      "prediction: 0.98, target value: 1\n",
      "prediction: 1.19, target value: 4\n",
      "prediction: 0.74, target value: 0\n",
      "prediction: 0.89, target value: 1\n",
      "prediction: 1.51, target value: 0\n",
      "prediction: 0.44, target value: 0\n",
      "prediction: 1.76, target value: 1\n",
      "prediction: 1.15, target value: 0\n",
      "prediction: 0.25, target value: 0\n",
      "prediction: 0.88, target value: 0\n",
      "prediction: 1.07, target value: 0\n",
      "prediction: 0.82, target value: 0\n",
      "prediction: 1.05, target value: 0\n",
      "prediction: -0.36, target value: 0\n",
      "prediction: 1.16, target value: 0\n",
      "prediction: 0.76, target value: 0\n",
      "prediction: 0.35, target value: 0\n",
      "prediction: 1.58, target value: 2\n",
      "prediction: 1.11, target value: 0\n",
      "prediction: 1.56, target value: 2\n",
      "prediction: 0.44, target value: 1\n",
      "prediction: 1.22, target value: 0\n",
      "prediction: 1.18, target value: 0\n",
      "prediction: 1.46, target value: 1\n",
      "prediction: 0.63, target value: 0\n",
      "prediction: 1.63, target value: 1\n",
      "prediction: 0.23, target value: 0\n",
      "prediction: 0.95, target value: 0\n",
      "prediction: 1.43, target value: 1\n",
      "prediction: 1.11, target value: 2\n",
      "prediction: 0.70, target value: 0\n",
      "prediction: 0.75, target value: 0\n",
      "prediction: 0.60, target value: 0\n",
      "prediction: 1.53, target value: 1\n",
      "prediction: 0.10, target value: 1\n",
      "prediction: 2.15, target value: 4\n",
      "prediction: 1.25, target value: 0\n",
      "prediction: 0.36, target value: 1\n",
      "prediction: 0.09, target value: 0\n",
      "prediction: 1.03, target value: 1\n",
      "prediction: 0.93, target value: 0\n",
      "prediction: -0.06, target value: 0\n",
      "prediction: 1.13, target value: 1\n",
      "prediction: 1.34, target value: 1\n",
      "prediction: 1.20, target value: 2\n",
      "prediction: 0.65, target value: 0\n",
      "prediction: 1.22, target value: 0\n",
      "prediction: 1.66, target value: 4\n",
      "prediction: 0.51, target value: 0\n",
      "prediction: 1.24, target value: 0\n",
      "prediction: 0.77, target value: 0\n",
      "prediction: 1.28, target value: 3\n",
      "prediction: 1.67, target value: 0\n",
      "prediction: 1.05, target value: 0\n",
      "prediction: 0.32, target value: 0\n",
      "prediction: 1.10, target value: 0\n",
      "prediction: 1.74, target value: 5\n",
      "prediction: 1.59, target value: 1\n",
      "prediction: 0.95, target value: 2\n",
      "prediction: 1.17, target value: 0\n",
      "prediction: 1.05, target value: 0\n",
      "prediction: -0.08, target value: 0\n",
      "prediction: 0.61, target value: 0\n",
      "prediction: 1.67, target value: 0\n",
      "prediction: 1.59, target value: 1\n",
      "prediction: 0.89, target value: 1\n",
      "prediction: 0.61, target value: 0\n",
      "prediction: 0.88, target value: 0\n",
      "prediction: 1.06, target value: 3\n",
      "prediction: 0.80, target value: 0\n",
      "prediction: 1.19, target value: 5\n",
      "prediction: 0.65, target value: 0\n",
      "prediction: 0.97, target value: 1\n",
      "prediction: 0.59, target value: 0\n",
      "prediction: 0.45, target value: 5\n",
      "prediction: 1.49, target value: 2\n",
      "prediction: 1.61, target value: 1\n",
      "prediction: 1.38, target value: 3\n",
      "prediction: 1.75, target value: 0\n",
      "prediction: 1.89, target value: 5\n",
      "prediction: 1.18, target value: 0\n",
      "prediction: 0.69, target value: 3\n",
      "prediction: 1.36, target value: 1\n",
      "prediction: 1.46, target value: 1\n",
      "prediction: 1.11, target value: 2\n",
      "prediction: 1.54, target value: 1\n",
      "prediction: 0.51, target value: 0\n",
      "prediction: 0.32, target value: 0\n",
      "prediction: 1.31, target value: 5\n",
      "prediction: 0.49, target value: 0\n",
      "prediction: 1.53, target value: 1\n",
      "prediction: 1.12, target value: 3\n",
      "prediction: 0.53, target value: 0\n",
      "prediction: 1.26, target value: 1\n",
      "prediction: 0.55, target value: 0\n",
      "prediction: 1.20, target value: 2\n",
      "prediction: 1.32, target value: 0\n",
      "prediction: 0.40, target value: 0\n",
      "prediction: 0.85, target value: 0\n",
      "prediction: 0.76, target value: 0\n",
      "prediction: 0.17, target value: 4\n",
      "prediction: 2.34, target value: 1\n",
      "prediction: 1.54, target value: 1\n",
      "prediction: 1.41, target value: 0\n",
      "prediction: 0.90, target value: 4\n",
      "prediction: 1.30, target value: 1\n",
      "prediction: -0.02, target value: 0\n",
      "prediction: 1.25, target value: 2\n",
      "prediction: 1.56, target value: 2\n",
      "prediction: 0.85, target value: 1\n",
      "prediction: 2.28, target value: 1\n",
      "prediction: 1.27, target value: 0\n",
      "prediction: 1.87, target value: 3\n",
      "prediction: 0.69, target value: 3\n",
      "prediction: 1.93, target value: 2\n",
      "prediction: 0.47, target value: 1\n",
      "prediction: 1.00, target value: 0\n",
      "prediction: 0.73, target value: 3\n",
      "prediction: 1.83, target value: 1\n",
      "prediction: 0.99, target value: 1\n",
      "prediction: 0.77, target value: 0\n",
      "prediction: 1.68, target value: 0\n",
      "prediction: 0.93, target value: 2\n",
      "prediction: 1.04, target value: 2\n",
      "prediction: 1.27, target value: 2\n",
      "prediction: 1.19, target value: 0\n",
      "prediction: 0.61, target value: 0\n",
      "prediction: 1.17, target value: 0\n",
      "prediction: 0.95, target value: 0\n",
      "prediction: 1.14, target value: 5\n",
      "prediction: 0.06, target value: 0\n",
      "prediction: 1.23, target value: 1\n",
      "prediction: 1.30, target value: 3\n",
      "prediction: 1.73, target value: 2\n",
      "prediction: 1.13, target value: 0\n",
      "prediction: 0.85, target value: 0\n",
      "prediction: 1.66, target value: 4\n",
      "prediction: 0.77, target value: 2\n",
      "prediction: 1.23, target value: 5\n",
      "prediction: 1.76, target value: 2\n",
      "prediction: -0.17, target value: 0\n",
      "prediction: 0.66, target value: 2\n",
      "prediction: 0.69, target value: 0\n",
      "prediction: 1.60, target value: 1\n",
      "prediction: 0.57, target value: 1\n",
      "prediction: 1.76, target value: 1\n",
      "prediction: 1.34, target value: 0\n",
      "prediction: 0.33, target value: 0\n",
      "prediction: 1.14, target value: 0\n",
      "prediction: 1.37, target value: 0\n",
      "prediction: 0.94, target value: 1\n",
      "prediction: 2.26, target value: 0\n",
      "prediction: 0.90, target value: 1\n",
      "prediction: 0.52, target value: 5\n",
      "prediction: 0.20, target value: 0\n",
      "prediction: 1.04, target value: 1\n",
      "prediction: 0.26, target value: 1\n",
      "prediction: 0.28, target value: 0\n",
      "prediction: 1.26, target value: 0\n",
      "prediction: 1.49, target value: 1\n",
      "prediction: 1.39, target value: 5\n",
      "prediction: 1.44, target value: 0\n",
      "prediction: 0.94, target value: 5\n",
      "prediction: 1.80, target value: 2\n",
      "prediction: 0.41, target value: 0\n",
      "prediction: 1.47, target value: 1\n",
      "prediction: 1.30, target value: 5\n",
      "prediction: 0.88, target value: 0\n",
      "prediction: 0.31, target value: 0\n",
      "prediction: 1.29, target value: 0\n",
      "prediction: 1.32, target value: 0\n",
      "prediction: 1.62, target value: 2\n",
      "prediction: 1.63, target value: 1\n",
      "prediction: 1.11, target value: 2\n",
      "prediction: 0.63, target value: 1\n",
      "prediction: 1.05, target value: 2\n",
      "prediction: 0.73, target value: 1\n",
      "prediction: 1.38, target value: 4\n",
      "prediction: 1.32, target value: 2\n",
      "prediction: 1.49, target value: 3\n",
      "prediction: 0.51, target value: 0\n",
      "prediction: 1.02, target value: 3\n"
     ]
    }
   ],
   "source": [
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
